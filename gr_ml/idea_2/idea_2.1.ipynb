{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2503c145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jose/anaconda3/envs/test/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67457d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9002982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a6e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afead72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d791762",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('my_data/fake_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18120f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>obj</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t  obj  x  y  z  vx  vy  vz\n",
       "0   0    1 -1 -1 -1  -1  -1  -1\n",
       "1   0    2 -2  0  0   0   2   3\n",
       "2   1    1 -1  1  1   1   1   3\n",
       "3   1    2 -2  2  2   2   2   3\n",
       "4   2    1 -1  3  3   3   1   3\n",
       "5   2    2 -2  4  4   4   2   3\n",
       "6   3    1 -1  5  5   5   1   3\n",
       "7   3    2 -3  6  6   6   2   3\n",
       "8   4    1 -4 -1 -1  -1  -1  -1\n",
       "9   4    2 -3  0  0   0   2   3\n",
       "10  5    1 -4  1  1   1   1   3\n",
       "11  5    2 -2  2  2   2   2   3\n",
       "12  6    1 -1  3  3   3   1   3\n",
       "13  6    2 -2  4  4   4   2   3\n",
       "14  7    1  1  5  5   5   1   3\n",
       "15  7    2  2  6  6   6   2   3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8031c77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3af0968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb3c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir: str, transform=None,maxnobjects=2,deep=0,\n",
    "                nfeatures=6, future_prediction=1):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.maxnobjects = maxnobjects\n",
    "        self.deep = deep\n",
    "        self.nfeatures = nfeatures\n",
    "        self.obj_id = list()\n",
    "        self.future_prediction = future_prediction\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data['t'].max()-self.data['t'].min() -self.deep+1 -self.future_predicition\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        #FOr image        \n",
    "        data = np.zeros((self.maxnobjects,self.nfeatures, self.deep+1))\n",
    "        #images = np.zeros((self.maxnobjects,1, self.deep))\n",
    "        \n",
    "\n",
    "        for t in range(self.deep+1):\n",
    "            query_data= self.data[self.data['t']== idx+t].iloc[:,1:]\n",
    "            objects_ids = np.array(query_data.iloc[:,0])\n",
    "            for oi,o_id in enumerate(objects_ids):\n",
    "                #print(o_id, \"in \", self.obj_id, \"time\", t)\n",
    "                ind = self.obj_id.index(o_id) if o_id in self.obj_id else -1\n",
    "                if ind != -1:\n",
    "                    #print(\"updating \", o_id, \" index \", ind)\n",
    "                    data[ind, :,t] = query_data.iloc[oi,1:]\n",
    "                else:\n",
    "                    #print (\"current ids\", self.obj_id, \" adding \", o_id)\n",
    "                    self.obj_id.append(o_id)\n",
    "                    new_id = len(self.obj_id)-1\n",
    "                    #print (new_id, \" -> NEW ID\")\n",
    "                    data[new_id, :,t] = query_data.iloc[oi,1:]\n",
    "            #print(objects_ids)#, query_data.iloc[:,2:-1])\n",
    "            #nobjects, _ = query_data.shape\n",
    "            #data[:nobjects,:,t] = query_data.iloc[:,1:]\n",
    "            #images.append(query_data.iloc[:,-1])\n",
    "            #images[:nobjects,0,t] = query_data.iloc[:,-1]\n",
    "        #print(data, data.shape)\n",
    "\n",
    "        image_path = os.path.join(self.root_dir, \n",
    "                                    str(self.future_prediction+1+self.deep)+\".jpg\")\n",
    "        image = cv2.imread(image_path)\n",
    "        #data = np.array(self.data.iloc[idx, 0:-1]).reshape(-1,8)\n",
    "        sample = {'image': image, 'data': data}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af721896",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset2(Dataset):\n",
    "    def __init__(self, csv_file, root_dir: str, transform=None,maxnobjects=2,\n",
    "                nfeatures=6, future_prediction=1):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.maxnobjects = maxnobjects\n",
    "        self.nfeatures = nfeatures\n",
    "        self.obj_id = list()\n",
    "        self.future_prediction = future_prediction\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data['t'].max()-self.data['t'].min()+1 -self.future_prediction\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        #FOr image        \n",
    "        data = np.zeros((self.maxnobjects,self.nfeatures, 1))\n",
    "        query_data= self.data[self.data['t']== idx].iloc[:,1:]\n",
    "        objects_ids = np.array(query_data.iloc[:,0])\n",
    "        for oi,o_id in enumerate(objects_ids):\n",
    "            ind = self.obj_id.index(o_id) if o_id in self.obj_id else -1\n",
    "            if ind != -1:\n",
    "                data[ind, :] = np.array(query_data.iloc[oi,1:]).reshape(self.nfeatures,1)\n",
    "            else:\n",
    "                self.obj_id.append(o_id)\n",
    "                new_id = len(self.obj_id)-1\n",
    "                data[new_id, :,0] = query_data.iloc[oi,1:]\n",
    "\n",
    "        image_path = os.path.join(self.root_dir, str(idx+\n",
    "                            self.future_prediction)+\".jpg\")\n",
    "        image = cv2.imread(image_path)\n",
    "        #data = np.array(self.data.iloc[idx, 0:-1]).reshape(-1,8)\n",
    "        sample = {'image': image, 'data': data}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548bb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, utils\n",
    "from skimage import transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d6a7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, data = sample['image'], sample['data']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        #data = data * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'data': data}\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, data = sample['image'], sample['data']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'data': torch.from_numpy(data)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea864ccf",
   "metadata": {},
   "source": [
    "#https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "078d6228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FROM TUTORIAL\n",
    "mytransform=transforms.Compose([\n",
    "                                Rescale(256),\n",
    "                                ToTensor()\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b27e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOr testing\n",
    "#shape maxobject, nfeatures, deep\n",
    "my_train_dataset = MyCustomDataset2(\"my_data/fake_data.csv\", \"my_data/images/train\", \n",
    "                                    transform=mytransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44198fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_dataset = MyCustomDataset2(\"my_data/fake_testdata.csv\", \"my_data/images/test\", \n",
    "                                   transform=mytransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "045cc8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "014d6d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INLINE torch.Size([3, 256, 341])\n",
      "INLINE torch.Size([3, 256, 341])\n",
      "INLINE torch.Size([3, 256, 341])\n",
      "INLINE torch.Size([3, 256, 341])\n",
      "INLINE torch.Size([3, 256, 341])\n",
      "INLINE torch.Size([3, 256, 341])\n",
      "INLINE torch.Size([3, 256, 341])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(my_train_dataset)):\n",
    "    print(\"INLINE\", my_train_dataset[i]['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a60e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(my_train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(my_test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f80a04b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader), len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7ae9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffcc10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow2(images):\n",
    "    grid = utils.make_grid(images)\n",
    "    plt.imshow(grid.numpy().transpose((1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53e8552e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "newdata = dataiter.next()\n",
    "images, data, = newdata[\"image\"], newdata[\"data\"]\n",
    "# show images\n",
    "#imshow(images[0])\n",
    "imshow2(images)\n",
    "# print labels\n",
    "#print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "277dee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "newdata = dataiter.next()\n",
    "test_image, test_data = newdata[\"image\"].to(device, dtype=torch.float), newdata[\"data\"].to(device, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7b6cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(3,10,kernel_size=3)\n",
    "        self.uconv1 = nn.ConvTranspose2d(2,10,kernel_size=(3,3))\n",
    "        self.uconv2 = nn.ConvTranspose2d(10,40,kernel_size=(5,5))\n",
    "        self.uconv3 = nn.ConvTranspose2d(40,3, kernel_size=(10,10))\n",
    "        #self.uconv4 = nn.ConvTranspose2d(60,256, kernel_size=(10,10), groups=1)\n",
    "        self.up1 = nn.Upsample(size=(256,256))#,scale_factor = 10)\n",
    "\n",
    "        #(2,10,kernel_size=3)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(12, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "    \n",
    "    def test(self,x):\n",
    "        print (x.shape)\n",
    "        x1 =  self.uconv3(self.uconv2(self.uconv1(x)))\n",
    "        print (x1.shape)\n",
    "        print (self.up1(x1).shape)\n",
    "\n",
    "    def forward(self, input1):\n",
    "        x = F.relu(self.uconv1(input1))\n",
    "        x = F.relu(self.uconv2(x))\n",
    "        x = F.relu(self.uconv3(x))\n",
    "        output1 = F.relu(self.up1(x))\n",
    "        print (output1.shape)\n",
    "\n",
    "        #x = self.pool(F.relu(self.conv1(x)))\n",
    "        #x = self.pool(F.relu(self.conv2(x)))\n",
    "        print(input1.shape)\n",
    "        x2 = torch.flatten(input1, 1) # flatten all dimensions except batch\n",
    "        #print(x.shape)\n",
    "        print(x2.shape)\n",
    "        x2 = F.self.fc1(x2)\n",
    "\n",
    "        x2 = F.relu(self.fc2(x2))\n",
    "        x2 = F.sigmoid(self.fc3(x2))\n",
    "        return [output1, x2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b49bb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (uconv1): ConvTranspose2d(2, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (uconv2): ConvTranspose2d(10, 40, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (uconv3): ConvTranspose2d(40, 3, kernel_size=(10, 10), stride=(1, 1))\n",
      "  (up1): Upsample(size=(256, 256), mode=nearest)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=12, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "623e7a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.],\n",
       "          [ 3.],\n",
       "          [ 3.],\n",
       "          [ 3.],\n",
       "          [ 1.],\n",
       "          [ 3.]],\n",
       "\n",
       "         [[-2.],\n",
       "          [ 4.],\n",
       "          [ 4.],\n",
       "          [ 4.],\n",
       "          [ 2.],\n",
       "          [ 3.]]],\n",
       "\n",
       "\n",
       "        [[[-4.],\n",
       "          [ 1.],\n",
       "          [ 1.],\n",
       "          [ 1.],\n",
       "          [ 1.],\n",
       "          [ 3.]],\n",
       "\n",
       "         [[-2.],\n",
       "          [ 2.],\n",
       "          [ 2.],\n",
       "          [ 2.],\n",
       "          [ 2.],\n",
       "          [ 3.]]],\n",
       "\n",
       "\n",
       "        [[[-1.],\n",
       "          [ 3.],\n",
       "          [ 3.],\n",
       "          [ 3.],\n",
       "          [ 1.],\n",
       "          [ 3.]],\n",
       "\n",
       "         [[-2.],\n",
       "          [ 4.],\n",
       "          [ 4.],\n",
       "          [ 4.],\n",
       "          [ 2.],\n",
       "          [ 3.]]],\n",
       "\n",
       "\n",
       "        [[[-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.]],\n",
       "\n",
       "         [[-2.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 2.],\n",
       "          [ 3.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "24a5a520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 256, 256])\n",
      "torch.Size([4, 2, 6, 1])\n",
      "torch.Size([4, 12])\n",
      " ** On entry to SGEMM  parameter number 10 had an illegal value\n",
      " ** On entry to SGEMM  parameter number 10 had an illegal value\n",
      " ** On entry to SGEMM  parameter number 10 had an illegal value\n",
      " ** On entry to SGEMM  parameter number 10 had an illegal value\n",
      " ** On entry to SGEMM  parameter number 10 had an illegal value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/anaconda3/envs/test/lib/python3.9/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0.0071, 0.0071, 0.0071,  ..., 0.0116, 0.0116, 0.0116],\n",
       "           [0.0071, 0.0071, 0.0071,  ..., 0.0116, 0.0116, 0.0116],\n",
       "           [0.0071, 0.0071, 0.0071,  ..., 0.0116, 0.0116, 0.0116],\n",
       "           ...,\n",
       "           [0.0016, 0.0016, 0.0016,  ..., 0.0063, 0.0063, 0.0063],\n",
       "           [0.0016, 0.0016, 0.0016,  ..., 0.0063, 0.0063, 0.0063],\n",
       "           [0.0016, 0.0016, 0.0016,  ..., 0.0063, 0.0063, 0.0063]],\n",
       " \n",
       "          [[0.0228, 0.0228, 0.0228,  ..., 0.0212, 0.0212, 0.0212],\n",
       "           [0.0228, 0.0228, 0.0228,  ..., 0.0212, 0.0212, 0.0212],\n",
       "           [0.0228, 0.0228, 0.0228,  ..., 0.0212, 0.0212, 0.0212],\n",
       "           ...,\n",
       "           [0.0175, 0.0175, 0.0175,  ..., 0.0183, 0.0183, 0.0183],\n",
       "           [0.0175, 0.0175, 0.0175,  ..., 0.0183, 0.0183, 0.0183],\n",
       "           [0.0175, 0.0175, 0.0175,  ..., 0.0183, 0.0183, 0.0183]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0063, 0.0063, 0.0063,  ..., 0.0101, 0.0101, 0.0101],\n",
       "           [0.0063, 0.0063, 0.0063,  ..., 0.0101, 0.0101, 0.0101],\n",
       "           [0.0063, 0.0063, 0.0063,  ..., 0.0101, 0.0101, 0.0101],\n",
       "           ...,\n",
       "           [0.0016, 0.0016, 0.0016,  ..., 0.0063, 0.0063, 0.0063],\n",
       "           [0.0016, 0.0016, 0.0016,  ..., 0.0063, 0.0063, 0.0063],\n",
       "           [0.0016, 0.0016, 0.0016,  ..., 0.0063, 0.0063, 0.0063]],\n",
       " \n",
       "          [[0.0232, 0.0232, 0.0232,  ..., 0.0212, 0.0212, 0.0212],\n",
       "           [0.0232, 0.0232, 0.0232,  ..., 0.0212, 0.0212, 0.0212],\n",
       "           [0.0232, 0.0232, 0.0232,  ..., 0.0212, 0.0212, 0.0212],\n",
       "           ...,\n",
       "           [0.0175, 0.0175, 0.0175,  ..., 0.0183, 0.0183, 0.0183],\n",
       "           [0.0175, 0.0175, 0.0175,  ..., 0.0183, 0.0183, 0.0183],\n",
       "           [0.0175, 0.0175, 0.0175,  ..., 0.0183, 0.0183, 0.0183]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0071, 0.0071, 0.0071,  ..., 0.0116, 0.0116, 0.0116],\n",
       "           [0.0071, 0.0071, 0.0071,  ..., 0.0116, 0.0116, 0.0116],\n",
       "           [0.0071, 0.0071, 0.0071,  ..., 0.0116, 0.0116, 0.0116],\n",
       "           ...,\n",
       "           [0.0016, 0.0016, 0.0016,  ..., 0.0063, 0.0063, 0.0063],\n",
       "           [0.0016, 0.0016, 0.0016,  ..., 0.0063, 0.0063, 0.0063],\n",
       "           [0.0016, 0.0016, 0.0016,  ..., 0.0063, 0.0063, 0.0063]],\n",
       " \n",
       "          [[0.0228, 0.0228, 0.0228,  ..., 0.0212, 0.0212, 0.0212],\n",
       "           [0.0228, 0.0228, 0.0228,  ..., 0.0212, 0.0212, 0.0212],\n",
       "           [0.0228, 0.0228, 0.0228,  ..., 0.0212, 0.0212, 0.0212],\n",
       "           ...,\n",
       "           [0.0175, 0.0175, 0.0175,  ..., 0.0183, 0.0183, 0.0183],\n",
       "           [0.0175, 0.0175, 0.0175,  ..., 0.0183, 0.0183, 0.0183],\n",
       "           [0.0175, 0.0175, 0.0175,  ..., 0.0183, 0.0183, 0.0183]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0071, 0.0071, 0.0071,  ..., 0.0116, 0.0116, 0.0116],\n",
       "           [0.0071, 0.0071, 0.0071,  ..., 0.0116, 0.0116, 0.0116],\n",
       "           [0.0071, 0.0071, 0.0071,  ..., 0.0116, 0.0116, 0.0116],\n",
       "           ...,\n",
       "           [0.0022, 0.0022, 0.0022,  ..., 0.0074, 0.0074, 0.0074],\n",
       "           [0.0022, 0.0022, 0.0022,  ..., 0.0074, 0.0074, 0.0074],\n",
       "           [0.0022, 0.0022, 0.0022,  ..., 0.0074, 0.0074, 0.0074]],\n",
       " \n",
       "          [[0.0228, 0.0228, 0.0228,  ..., 0.0212, 0.0212, 0.0212],\n",
       "           [0.0228, 0.0228, 0.0228,  ..., 0.0212, 0.0212, 0.0212],\n",
       "           [0.0228, 0.0228, 0.0228,  ..., 0.0212, 0.0212, 0.0212],\n",
       "           ...,\n",
       "           [0.0184, 0.0184, 0.0184,  ..., 0.0174, 0.0174, 0.0174],\n",
       "           [0.0184, 0.0184, 0.0184,  ..., 0.0174, 0.0174, 0.0174],\n",
       "           [0.0184, 0.0184, 0.0184,  ..., 0.0174, 0.0174, 0.0174]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
       "        device='cuda:0', grad_fn=<ReluBackward0>),\n",
       " tensor([[0.5123],\n",
       "         [0.4911],\n",
       "         [0.5123],\n",
       "         [0.4686]], device='cuda:0', grad_fn=<SigmoidBackward>)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,val_data):\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_data, 0):\n",
    "            # get the inputs; data is a st of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # zero the parameter gradients\n",
    "            #optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss +=loss.item()\n",
    "    return val_loss/len(val_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c761739",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a st of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f'  %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    val_loss = validate(net, testloader)\n",
    "    print('[%d, %5d] epoch loss: %.3f validation loss: %.3f'  %\n",
    "        (epoch + 1, i + 1, epoch_loss / len(trainloader), val_loss))\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d1d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b5dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55e9a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7b9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817479e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
