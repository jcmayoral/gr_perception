{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model From https://github.com/fxia22/pointnet.pytorch/blob/master/pointnet/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 500])\n"
     ]
    }
   ],
   "source": [
    "#batch, dim, npoints\n",
    "sim_data = Variable(torch.rand(32,3,500))\n",
    "print(sim_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "\n",
    "\n",
    "# prepare some coordinates\n",
    "x, y, z = np.indices((8, 8, 3))\n",
    "\n",
    "# draw cuboids in the top left and bottom right corners, and a link between them\n",
    "cube1 = (x < 1) & (y < 1) & (z < 1)\n",
    "cube2 = (x >= 2) & (y >= 2) & (z >= 2)\n",
    "link = abs(x - y) + abs(y - z) + abs(z - x) <= 2\n",
    "\n",
    "# combine the objects into a single boolean array\n",
    "voxels = cube1 | cube2 | link\n",
    "\n",
    "# set the colors of each object\n",
    "colors = np.empty(voxels.shape, dtype=object)\n",
    "colors[link] = 'red'\n",
    "colors[cube1] = 'blue'\n",
    "colors[cube2] = 'green'\n",
    "print(colors.shape)\n",
    "\n",
    "# and plot everything\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.voxels(voxels, facecolors=colors, edgecolor='k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/meder411/PointNet-PyTorch/blob/master/models/transformer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as grad\n",
    "\n",
    "\n",
    "\n",
    "##-----------------------------------------------------------------------------\n",
    "# Class for Transformer. Subclasses PyTorch's own \"nn\" module\n",
    "#\n",
    "# Computes a KxK affine transform from the input data to transform inputs\n",
    "# to a \"canonical view\"\n",
    "##\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_points=2000, K=3):\n",
    "        # Call the super constructor\n",
    "        print (num_points, K)\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # Number of dimensions of the data\n",
    "        self.K = K\n",
    "\n",
    "        # Size of input\n",
    "        self.N = num_points\n",
    "        if num_points < 201:\n",
    "            print (\"this will fail too small resize to minimum of 201\")\n",
    "            self.N = 201\n",
    "\n",
    "        # Initialize identity matrix on the GPU (do this here so it only \n",
    "        # happens once)\n",
    "        self.identity = grad.Variable(\n",
    "            torch.eye(self.K).double().view(-1).cuda())\n",
    "\n",
    "        # First embedding block\n",
    "        self.block1 =nn.Sequential(\n",
    "            nn.Conv1d(K, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU())\n",
    "\n",
    "        # Second embedding block\n",
    "        self.block2 =nn.Sequential(\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU())\n",
    "\n",
    "        # Third embedding block\n",
    "        self.block3 =nn.Sequential(\n",
    "            nn.Conv1d(128, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU())\n",
    "\n",
    "        # Multilayer perceptron\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(64, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, K * K))\n",
    "\n",
    "\n",
    "    # Take as input a B x K x N matrix of B batches of N points with K \n",
    "    # dimensions\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Compute the feature extractions\n",
    "        # Output should ultimately be B x 1024 x N\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        # Pool over the number of points\n",
    "        # Output should be B x 1024 x 1 --> B x 1024 (after squeeze)\n",
    "        x = F.max_pool1d(x, self.N).squeeze(2)\n",
    "        # Run the pooled features through the multi-layer perceptron\n",
    "        # Output should be B x K^2\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        # Add identity matrix to transform\n",
    "        # Output is still B x K^2 (broadcasting takes care of batch dimension)\n",
    "        x += self.identity\n",
    "\n",
    "        # Reshape the output into B x K x K affine transformation matrices\n",
    "        x = x.view(-1, self.K, self.K)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_data = Variable(torch.rand(32,3,400)).cuda()\n",
    "sim_data2 = Variable(torch.rand(32,3,350)).cuda()\n",
    "t = Transformer(num_points=201, K=3).cuda()\n",
    "t(sim_data2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t(sim_data2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_data = Variable(torch.rand(32,3,4000)).cuda()\n",
    "#t = Transformer(num_points=2500, K=3).cuda()\n",
    "#t(sim_data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source https://discuss.pytorch.org/t/which-part-of-pytorch-tensor-represents-channels/21778\n",
    "The first number represents the Batchsize (N) and for tensors holding data of a dimension of 1 or above the next dimension is usually referred to as channel-dimension. The following dimensions are commonly height, width and depth.\n",
    "So for 2d data (images) you have a 4d tensor of NxCxHxW which you feed into a 2d conv layer.\n",
    "\n",
    "Note that channels only exist for convolutional layers. Linear layers for example need a shape of N x #num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "import random\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path=\"\", pointsnumber=1000):\n",
    "        #how many pointclouds\n",
    "        self.nsamples = pointsnumber\n",
    "        self.random = random\n",
    "        self.pointsnumber = pointsnumber\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        x = np.zeros((3, self.nsamples), dtype=np.double)\n",
    "        y = 1\n",
    "        return (x,1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl,nsamples):\n",
    "        self.dl = dl\n",
    "        self.func = self.tocuda\n",
    "        self.batchsize = len(self.dl)\n",
    "        self.nsamples = nsamples\n",
    "    \n",
    "    def tocuda(self,x,y):\n",
    "        return x.cuda(), y.cuda()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR train_ds = TensorDataset(x_train, y_train)\n",
    "\n",
    "def get_data(train_ds, valid_ds, bs, nsamples):\n",
    "    return (\n",
    "        WrappedDataLoader(DataLoader(train_ds, batch_size=bs), nsamples),\n",
    "        WrappedDataLoader(DataLoader(valid_ds, batch_size=bs), nsamples),\n",
    "    )\n",
    "\n",
    "#gen = DataLoader(TensorDataset(data, labels), batch_size=25, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsnumber = 1500\n",
    "batchsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "itdataset = MyDataset(pointsnumber=pointsnumber)\n",
    "traingen, valgen = get_data(itdataset,itdataset,bs=batchsize, nsamples=itdataset.nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, n_points=500):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.n_points = n_points\n",
    "        self.transformer = Transformer(150)\n",
    "        self.conv1 = torch.nn.Conv1d(3, 32, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(32, 16, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(16, 1, 1)\n",
    "        self.lin1 = torch.nn.Linear(30, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=0.01, momentum=0.2)\n",
    "        self.batch_loss = list()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        #remove\n",
    "        x = x[:,:,:random.randint(202,250)]\n",
    "        \n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #x = torch.max(x, 2, keepdim=True)\n",
    "        #x = x.view(batchsize,-1)\n",
    "        x = x.flatten()\n",
    "        x = F.relu(self.lin1(x))\n",
    "        #print(x.item(), \"TEST\")\n",
    "        return x\n",
    "\n",
    "    def trainbatch(self,x,targets,batchid):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.__call__(x)\n",
    "        \n",
    "        loss = self.criterion(output,targets)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self.epoch_loss += loss.item()\n",
    "        self.batch_loss.append(loss.item())\n",
    "\n",
    "        #print(\"Batch {} - batch loss: {}\".format(batchid, loss.item()))\n",
    "\n",
    "    def mytrain(self,traindata,valdata,nepochs=5,valsamples=10, device=\"cuda\"):\n",
    "        epoch_loss = list()\n",
    "        #self.batch_loss = list()\n",
    "        self.train()\n",
    "\n",
    "        for epoch in range(nepochs):\n",
    "\n",
    "            self.epoch_loss = 0.0\n",
    "\n",
    "            #batches number\n",
    "            for b,x in enumerate(traindata):\n",
    "                self.trainbatch(x[0].float(),x[1].float(),b)\n",
    "\n",
    "            self.epoch_loss /= traindata.nsamples\n",
    "            \n",
    "            print(\"Epoch {} - epoch loss: {}\".format(epoch, self.epoch_loss), end=\" \")\n",
    "            epoch_loss.append(self.epoch_loss)\n",
    "\n",
    "            #validation\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_loss = sum(self.criterion(self.__call__(xb.float()), yb.float()) for xb, yb in valdata)\n",
    "            print(\" validation loss {}\".format(valid_loss/valdata.nsamples), sep=\"..\")\n",
    "        return epoch_loss\n",
    "\n",
    "    def predict(self,x):\n",
    "        with torch.no_grad():\n",
    "            return self.__call__(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note from pytorch tutorial for validation\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "...\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "    )\n",
    "    val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 3\n",
      "this will fail too small resize to minimum of 201\n"
     ]
    }
   ],
   "source": [
    "mymodel = MyModel(n_points=pointsnumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - epoch loss: 0.0009111337745876397  validation loss 872937226240.0\n",
      "Epoch 1 - epoch loss: 5819572333.326  validation loss 0.10000000149011612\n",
      "Epoch 2 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 3 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 4 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 5 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 6 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 7 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 8 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 9 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 10 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 11 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 12 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 13 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 14 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 15 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 16 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 17 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 18 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 19 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 20 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 21 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 22 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 23 - epoch loss: 0.1  validation loss 0.10000000149011612\n",
      "Epoch 24 - epoch loss: 0.1  validation loss 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    #sim_data = Variable(torch.rand(2,3,1))\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    #y = torch.ones_like(sim_data, device=device)  # directly create a tensor on GPU\n",
    "    #x = sim_data.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    #print(x)\n",
    "    #print(x.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n",
    "    mymodel.cuda()\n",
    "#print(device)\n",
    "losses = mymodel.mytrain(traingen, valgen,nepochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(torch.randint(0,10,(10,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparams = list(mymodel.parameters())\\nprint(len(params))\\nprint(params[0].size())\\nacc = np.sum([i.sum().cpu().detach().numpy() for i in params])\\nprint([i.sum().cpu().detach().numpy() for i in params])\\nprint(acc)\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\"\"\"\n",
    "params = list(mymodel.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())\n",
    "acc = np.sum([i.sum().cpu().detach().numpy() for i in params])\n",
    "print([i.sum().cpu().detach().numpy() for i in params])\n",
    "print(acc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f43f0298b00>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f43f02180b8>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(mymodel.batch_loss)), mymodel.batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "MSE 2.7555952072143555\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "x = Variable(torch.rand(batchsize,3,mymodel.n_points)).to(device)\n",
    "targets = torch.rand((batchsize,1)).to(device)\n",
    "y_pred = mymodel.predict(x)\n",
    "print(\"MSE {}\".format(((targets - y_pred)**2).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING TENSORBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('scalar/testingtensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(-360, 360):\n",
    "    angle_rad = step * math.pi / 180\n",
    "    writer.add_scalar('sin', math.sin(angle_rad)*step, step)\n",
    "    writer.add_scalar('cos', math.cos(angle_rad)*step, step)\n",
    "    writer.add_scalars('sin and cos', {'sin': math.sin(angle_rad), 'cos': math.cos(angle_rad)}, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(traingen)\n",
    "databatch, labels = next(dataiter)\n",
    "writer.add_graph(mymodel, databatch.float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 5\n",
    "for i in range(100):\n",
    "    writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r),\n",
    "                                    'xcosx':i*np.cos(i/r),\n",
    "                                    'tanx': np.tan(i/r)}, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "for step in range(5):\n",
    "    writer.add_histogram('hist-numpy', np.random.normal(0, sigma, 1000), step)\n",
    "    sigma += 1\n",
    "sigma = 1\n",
    "for step in range(5):\n",
    "    torch_normal = torch.distributions.Normal(0, sigma)\n",
    "    writer.add_histogram('hist-torch', torch_normal.sample((1, 1000)), step)\n",
    "    sigma += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand((10,3,20,20))\n",
    "labels = torch.ones(10,1,400)\n",
    "#perm = torch.randperm(5)\n",
    "#data = data[perm]\n",
    "#data = data.view(100,-1)\n",
    "#data = data.squeeze(0)\n",
    "out = torch.rand((10,20*20*3,2))#.flatten()\n",
    "#features.shape, data.shape, labels.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\"\"\"\n",
    "print(out.shape, out.size(0), out.ndim, data.size(0))\n",
    "print(data.shape, data.ndim, data.shape[1], data.size(0))\n",
    "print(labels.shape, labels.ndim)\n",
    "writer.add_embedding\n",
    "#(data.squeeze(0),\n",
    "#                    metadata=labels.squeeze(0),\n",
    "#                    label_img=data,#.squeeze(0),\n",
    "#                    global_step=1)\n",
    "writer.close()\n",
    "\"\"\"\n",
    "\n",
    "#HELP\n",
    "\"\"\"\n",
    "   print(\"loss_value:{}\".format(loss_value.data.item()))\n",
    "            # we need 3 dimension for tensor to visualize it!\n",
    "            out = torch.cat((out.data, torch.ones(len(out), 1)), 1)\n",
    "            writer.add_embedding(\n",
    "                out,\n",
    "                metadata=label_batch.data,\n",
    "                label_img=data_batch.data,\n",
    "                global_step=n_iter)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
