{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model From https://github.com/fxia22/pointnet.pytorch/blob/master/pointnet/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stn torch.Size([32, 3, 3])\n",
      "loss tensor(2.0153, grad_fn=<MeanBackward0>)\n",
      "stn64d torch.Size([32, 64, 64])\n",
      "loss tensor(125.9736, grad_fn=<MeanBackward0>)\n",
      "global feat torch.Size([32, 1024])\n",
      "point feat torch.Size([32, 1088, 2500])\n",
      "class torch.Size([32, 5])\n",
      "seg torch.Size([32, 2500, 3])\n"
     ]
    }
   ],
   "source": [
    "class STN3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STN3d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.array([1,0,0,0,1,0,0,0,1]).astype(np.float32))).view(1,9).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3)\n",
    "        return x\n",
    "\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(STNkd, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k*k)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1,self.k*self.k).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "class PointNetfeat(nn.Module):\n",
    "    def __init__(self, global_feat = True, feature_transform = False):\n",
    "        super(PointNetfeat, self).__init__()\n",
    "        self.stn = STN3d()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            self.fstn = STNkd(k=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_pts = x.size()[2]\n",
    "        trans = self.stn(x)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = torch.bmm(x, trans)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2,1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2,1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat\n",
    "\n",
    "class PointNetCls(nn.Module):\n",
    "    def __init__(self, k=2, feature_transform=False):\n",
    "        super(PointNetCls, self).__init__()\n",
    "        self.feature_transform = feature_transform\n",
    "        self.feat = PointNetfeat(global_feat=True, feature_transform=feature_transform)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.dropout(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x, trans, trans_feat\n",
    "        #return F.log_softmax(x, dim=1), trans, trans_feat\n",
    "\n",
    "\n",
    "class PointNetDenseCls(nn.Module):\n",
    "    def __init__(self, k = 2, feature_transform=False):\n",
    "        super(PointNetDenseCls, self).__init__()\n",
    "        self.k = k\n",
    "        self.feature_transform=feature_transform\n",
    "        self.feat = PointNetfeat(global_feat=False, feature_transform=feature_transform)\n",
    "        self.conv1 = torch.nn.Conv1d(1088, 512, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 128, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(128, self.k, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        n_pts = x.size()[2]\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x)\n",
    "        x = x.transpose(2,1).contiguous()\n",
    "        #x = F.log_softmax(x.view(-1,self.k), dim=-1)\n",
    "        x = x.view(batchsize, n_pts, self.k)\n",
    "        return x, trans, trans_feat\n",
    "\n",
    "def feature_transform_regularizer(trans):\n",
    "    d = trans.size()[1]\n",
    "    batchsize = trans.size()[0]\n",
    "    I = torch.eye(d)[None, :, :]\n",
    "    if trans.is_cuda:\n",
    "        I = I.cuda()\n",
    "    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2,1)) - I, dim=(1,2)))\n",
    "    return loss\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sim_data = Variable(torch.rand(32,3,2500))\n",
    "    trans = STN3d()\n",
    "    out = trans(sim_data)\n",
    "    print('stn', out.size())\n",
    "    print('loss', feature_transform_regularizer(out))\n",
    "\n",
    "    sim_data_64d = Variable(torch.rand(32, 64, 2500))\n",
    "    trans = STNkd(k=64)\n",
    "    out = trans(sim_data_64d)\n",
    "    print('stn64d', out.size())\n",
    "    print('loss', feature_transform_regularizer(out))\n",
    "\n",
    "    pointfeat = PointNetfeat(global_feat=True)\n",
    "    out, _, _ = pointfeat(sim_data)\n",
    "    print('global feat', out.size())\n",
    "\n",
    "    pointfeat = PointNetfeat(global_feat=False)\n",
    "    out, _, _ = pointfeat(sim_data)\n",
    "    print('point feat', out.size())\n",
    "\n",
    "    cls = PointNetCls(k = 5)\n",
    "    out, _, _ = cls(sim_data)\n",
    "    print('class', out.size())\n",
    "\n",
    "    seg = PointNetDenseCls(k = 3)\n",
    "    out, _, _ = seg(sim_data)\n",
    "    print('seg', out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 500])\n",
      "3\n",
      "torch.Size([32, 500, 1])\n",
      "torch.Size([32, 3, 3])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#batch, dim, npoints\n",
    "sim_data = Variable(torch.rand(32,3,500))\n",
    "print(sim_data.shape)\n",
    "classifier = PointNetDenseCls(k=1, feature_transform=None)\n",
    "output = classifier(sim_data)\n",
    "print(len(output))\n",
    "print (output[0].shape)\n",
    "print (output[1].shape)\n",
    "print (output[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn3d=STN3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "\n",
    "\n",
    "# prepare some coordinates\n",
    "x, y, z = np.indices((8, 8, 3))\n",
    "\n",
    "# draw cuboids in the top left and bottom right corners, and a link between them\n",
    "cube1 = (x < 1) & (y < 1) & (z < 1)\n",
    "cube2 = (x >= 2) & (y >= 2) & (z >= 2)\n",
    "link = abs(x - y) + abs(y - z) + abs(z - x) <= 2\n",
    "\n",
    "# combine the objects into a single boolean array\n",
    "voxels = cube1 | cube2 | link\n",
    "\n",
    "# set the colors of each object\n",
    "colors = np.empty(voxels.shape, dtype=object)\n",
    "colors[link] = 'red'\n",
    "colors[cube1] = 'blue'\n",
    "colors[cube2] = 'green'\n",
    "print(colors.shape)\n",
    "\n",
    "# and plot everything\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.voxels(voxels, facecolors=colors, edgecolor='k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source https://discuss.pytorch.org/t/which-part-of-pytorch-tensor-represents-channels/21778\n",
    "The first number represents the Batchsize (N) and for tensors holding data of a dimension of 1 or above the next dimension is usually referred to as channel-dimension. The following dimensions are commonly height, width and depth.\n",
    "So for 2d data (images) you have a 4d tensor of NxCxHxW which you feed into a 2d conv layer.\n",
    "\n",
    "Note that channels only exist for convolutional layers. Linear layers for example need a shape of N x #num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path=\"\", pointsnumber=100):\n",
    "        #how many pointclouds\n",
    "        self.nsamples = 1000\n",
    "        self.pointsnumber = pointsnumber\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        x = np.zeros((3,pointsnumber), dtype=np.double)\n",
    "        y = 1\n",
    "        return (x,1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl,nsamples):\n",
    "        self.dl = dl\n",
    "        self.func = self.tocuda\n",
    "        self.batchsize = len(self.dl)\n",
    "        self.nsamples = nsamples\n",
    "    \n",
    "    def tocuda(self,x,y):\n",
    "        return x.cuda(), y.cuda()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR train_ds = TensorDataset(x_train, y_train)\n",
    "\n",
    "def get_data(train_ds, valid_ds, bs, nsamples):\n",
    "    return (\n",
    "        WrappedDataLoader(DataLoader(train_ds, batch_size=bs), nsamples),\n",
    "        WrappedDataLoader(DataLoader(valid_ds, batch_size=bs * 2), nsamples),\n",
    "    )\n",
    "\n",
    "#gen = DataLoader(TensorDataset(data, labels), batch_size=25, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsnumber = 100\n",
    "batchsize = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "itdataset = MyDataset(pointsnumber=pointsnumber)\n",
    "traingen, valgen = get_data(itdataset,itdataset,bs=batchsize, nsamples=itdataset.nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, n_points=50):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.n_points = n_points\n",
    "        self.conv1 = torch.nn.Conv1d(3, 32, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(32, 16, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(16, 1, 1)\n",
    "        self.lin1 = torch.nn.Linear(n_points, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=0.01, momentum=0.2)\n",
    "        self.batch_loss = list()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #x = torch.max(x, 2, keepdim=True)\n",
    "        x = x.view(batchsize,-1)\n",
    "        #x = x.flatten()\n",
    "        x = F.relu(self.lin1(x))\n",
    "        #print(x.item(), \"TEST\")\n",
    "        return x\n",
    "\n",
    "    def trainbatch(self,x,targets,batchid):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.__call__(x)\n",
    "        \n",
    "        loss = self.criterion(output,targets)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self.epoch_loss += loss.item()\n",
    "        self.batch_loss.append(loss.item())\n",
    "\n",
    "        #print(\"Batch {} - batch loss: {}\".format(batchid, loss.item()))\n",
    "\n",
    "    def mytrain(self,traindata,valdata,nepochs=5,valsamples=10, device=\"cuda\"):\n",
    "        epoch_loss = list()\n",
    "        #self.batch_loss = list()\n",
    "        self.train()\n",
    "\n",
    "        for epoch in range(nepochs):\n",
    "\n",
    "            self.epoch_loss = 0.0\n",
    "\n",
    "            #batches number\n",
    "            for b,x in enumerate(traindata):\n",
    "                self.trainbatch(x[0].float(),x[1].float(),b)\n",
    "\n",
    "            self.epoch_loss /= traindata.nsamples\n",
    "            \n",
    "            print(\"Epoch {} - epoch loss: {}\".format(epoch, self.epoch_loss), end=\" \")\n",
    "            epoch_loss.append(self.epoch_loss)\n",
    "\n",
    "            #validation\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_loss = sum(self.criterion(self.__call__(xb.float()), yb.float()) for xb, yb in valdata)\n",
    "            print(\" validation loss {}\".format(valid_loss/valdata.nsamples), sep=\"..\")\n",
    "        return epoch_loss\n",
    "\n",
    "    def predict(self,x):\n",
    "        with torch.no_grad():\n",
    "            return self.__call__(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note from pytorch tutorial for validation\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "...\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "    )\n",
    "    val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = MyModel(n_points=pointsnumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - epoch loss: 1.3843160803237887e-05  validation loss 0.00015201850328594446\n",
      "Epoch 1 - epoch loss: 0.008973854941315949  validation loss 0.0027105396147817373\n",
      "Epoch 2 - epoch loss: 0.003486547015607357  validation loss 0.0009780190885066986\n",
      "Epoch 3 - epoch loss: 0.0012580185644328595  validation loss 0.0003528896486386657\n",
      "Epoch 4 - epoch loss: 0.00045391925051808355  validation loss 0.0001273298403248191\n",
      "Epoch 5 - epoch loss: 0.00016378331882879138  validation loss 4.594317215378396e-05\n",
      "Epoch 6 - epoch loss: 5.9096406097523865e-05  validation loss 1.6577190763200633e-05\n",
      "Epoch 7 - epoch loss: 2.132311410969123e-05  validation loss 5.981409685773542e-06\n",
      "Epoch 8 - epoch loss: 7.693801206187345e-06  validation loss 2.1582006866083248e-06\n",
      "Epoch 9 - epoch loss: 2.776040229946375e-06  validation loss 7.78701689796435e-07\n",
      "Epoch 10 - epoch loss: 1.0016310807259288e-06  validation loss 2.8096806659050344e-07\n",
      "Epoch 11 - epoch loss: 3.614132483562571e-07  validation loss 1.0138364103795539e-07\n",
      "Epoch 12 - epoch loss: 1.304113338846946e-07  validation loss 3.6580164675115157e-08\n",
      "Epoch 13 - epoch loss: 4.7052184754647893e-08  validation loss 1.3197870352144037e-08\n",
      "Epoch 14 - epoch loss: 1.6975647895378642e-08  validation loss 4.7615920095722686e-09\n",
      "Epoch 15 - epoch loss: 6.124261290096911e-09  validation loss 1.7175312283512767e-09\n",
      "Epoch 16 - epoch loss: 2.20925433325192e-09  validation loss 6.19853612882082e-10\n",
      "Epoch 17 - epoch loss: 7.975513476310425e-10  validation loss 2.2382452835589817e-10\n",
      "Epoch 18 - epoch loss: 2.8774412186294286e-10  validation loss 8.068384155235364e-11\n",
      "Epoch 19 - epoch loss: 1.0378222792262193e-10  validation loss 2.909761494251928e-11\n",
      "Epoch 20 - epoch loss: 3.7320180390487676e-11  validation loss 1.0436594297114077e-11\n",
      "Epoch 21 - epoch loss: 1.3406680238192692e-11  validation loss 3.752553823233029e-12\n",
      "Epoch 22 - epoch loss: 4.832092059814386e-12  validation loss 1.3648104998584265e-12\n",
      "Epoch 23 - epoch loss: 1.7495160806180188e-12  validation loss 4.946798721518209e-13\n",
      "Epoch 24 - epoch loss: 6.326388302113628e-13  validation loss 1.7909230955875932e-13\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    #sim_data = Variable(torch.rand(2,3,1))\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    #y = torch.ones_like(sim_data, device=device)  # directly create a tensor on GPU\n",
    "    #x = sim_data.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    #print(x)\n",
    "    #print(x.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n",
    "    mymodel.cuda()\n",
    "#print(device)\n",
    "losses = mymodel.mytrain(traingen, valgen,nepochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(torch.randint(0,10,(10,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparams = list(mymodel.parameters())\\nprint(len(params))\\nprint(params[0].size())\\nacc = np.sum([i.sum().cpu().detach().numpy() for i in params])\\nprint([i.sum().cpu().detach().numpy() for i in params])\\nprint(acc)\\n'"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\"\"\"\n",
    "params = list(mymodel.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())\n",
    "acc = np.sum([i.sum().cpu().detach().numpy() for i in params])\n",
    "print([i.sum().cpu().detach().numpy() for i in params])\n",
    "print(acc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8810706908>]"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8810854e48>]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(mymodel.batch_loss)), mymodel.batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "MSE 8.25526237487793\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "x = Variable(torch.rand(20,3,mymodel.n_points)).to(device)\n",
    "targets = torch.rand((20,1)).to(device)\n",
    "y_pred = mymodel.predict(x)\n",
    "print(\"MSE {}\".format(((targets - y_pred)**2).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING TENSORBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('scalar/testingtensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(-360, 360):\n",
    "    angle_rad = step * math.pi / 180\n",
    "    writer.add_scalar('sin', math.sin(angle_rad)*step, step)\n",
    "    writer.add_scalar('cos', math.cos(angle_rad)*step, step)\n",
    "    writer.add_scalars('sin and cos', {'sin': math.sin(angle_rad), 'cos': math.cos(angle_rad)}, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(traingen)\n",
    "databatch, labels = next(dataiter)\n",
    "writer.add_graph(mymodel, databatch.float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 5\n",
    "for i in range(100):\n",
    "    writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r),\n",
    "                                    'xcosx':i*np.cos(i/r),\n",
    "                                    'tanx': np.tan(i/r)}, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "for step in range(5):\n",
    "    writer.add_histogram('hist-numpy', np.random.normal(0, sigma, 1000), step)\n",
    "    sigma += 1\n",
    "sigma = 1\n",
    "for step in range(5):\n",
    "    torch_normal = torch.distributions.Normal(0, sigma)\n",
    "    writer.add_histogram('hist-torch', torch_normal.sample((1, 1000)), step)\n",
    "    sigma += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand((10,3,20,20))\n",
    "labels = torch.ones(10,1,400)\n",
    "#perm = torch.randperm(5)\n",
    "#data = data[perm]\n",
    "#data = data.view(100,-1)\n",
    "#data = data.squeeze(0)\n",
    "out = torch.rand((10,20*20*3,2))#.flatten()\n",
    "#features.shape, data.shape, labels.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(out.shape, out.size(0), out.ndim, data.size(0))\\nprint(data.shape, data.ndim, data.shape[1], data.size(0))\\nprint(labels.shape, labels.ndim)\\nwriter.add_embedding\\n#(data.squeeze(0),\\n#                    metadata=labels.squeeze(0),\\n#                    label_img=data,#.squeeze(0),\\n#                    global_step=1)\\nwriter.close()\\n'"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO\n",
    "\"\"\"\n",
    "print(out.shape, out.size(0), out.ndim, data.size(0))\n",
    "print(data.shape, data.ndim, data.shape[1], data.size(0))\n",
    "print(labels.shape, labels.ndim)\n",
    "writer.add_embedding\n",
    "#(data.squeeze(0),\n",
    "#                    metadata=labels.squeeze(0),\n",
    "#                    label_img=data,#.squeeze(0),\n",
    "#                    global_step=1)\n",
    "writer.close()\n",
    "\"\"\"\n",
    "\n",
    "#HELP\n",
    "\"\"\"\n",
    "   print(\"loss_value:{}\".format(loss_value.data.item()))\n",
    "            # we need 3 dimension for tensor to visualize it!\n",
    "            out = torch.cat((out.data, torch.ones(len(out), 1)), 1)\n",
    "            writer.add_embedding(\n",
    "                out,\n",
    "                metadata=label_batch.data,\n",
    "                label_img=data_batch.data,\n",
    "                global_step=n_iter)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
