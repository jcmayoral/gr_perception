{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model From https://github.com/fxia22/pointnet.pytorch/blob/master/pointnet/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stn torch.Size([32, 3, 3])\n",
      "loss tensor(1.9990, grad_fn=<MeanBackward0>)\n",
      "stn64d torch.Size([32, 64, 64])\n",
      "loss tensor(128.4727, grad_fn=<MeanBackward0>)\n",
      "global feat torch.Size([32, 1024])\n",
      "point feat torch.Size([32, 1088, 2500])\n",
      "class torch.Size([32, 5])\n",
      "seg torch.Size([32, 2500, 3])\n"
     ]
    }
   ],
   "source": [
    "class STN3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STN3d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.array([1,0,0,0,1,0,0,0,1]).astype(np.float32))).view(1,9).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3)\n",
    "        return x\n",
    "\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(STNkd, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k*k)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1,self.k*self.k).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "class PointNetfeat(nn.Module):\n",
    "    def __init__(self, global_feat = True, feature_transform = False):\n",
    "        super(PointNetfeat, self).__init__()\n",
    "        self.stn = STN3d()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            self.fstn = STNkd(k=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_pts = x.size()[2]\n",
    "        trans = self.stn(x)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = torch.bmm(x, trans)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2,1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2,1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat\n",
    "\n",
    "class PointNetCls(nn.Module):\n",
    "    def __init__(self, k=2, feature_transform=False):\n",
    "        super(PointNetCls, self).__init__()\n",
    "        self.feature_transform = feature_transform\n",
    "        self.feat = PointNetfeat(global_feat=True, feature_transform=feature_transform)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.dropout(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x, trans, trans_feat\n",
    "        #return F.log_softmax(x, dim=1), trans, trans_feat\n",
    "\n",
    "\n",
    "class PointNetDenseCls(nn.Module):\n",
    "    def __init__(self, k = 2, feature_transform=False):\n",
    "        super(PointNetDenseCls, self).__init__()\n",
    "        self.k = k\n",
    "        self.feature_transform=feature_transform\n",
    "        self.feat = PointNetfeat(global_feat=False, feature_transform=feature_transform)\n",
    "        self.conv1 = torch.nn.Conv1d(1088, 512, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 128, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(128, self.k, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        n_pts = x.size()[2]\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x)\n",
    "        x = x.transpose(2,1).contiguous()\n",
    "        #x = F.log_softmax(x.view(-1,self.k), dim=-1)\n",
    "        x = x.view(batchsize, n_pts, self.k)\n",
    "        return x, trans, trans_feat\n",
    "\n",
    "def feature_transform_regularizer(trans):\n",
    "    d = trans.size()[1]\n",
    "    batchsize = trans.size()[0]\n",
    "    I = torch.eye(d)[None, :, :]\n",
    "    if trans.is_cuda:\n",
    "        I = I.cuda()\n",
    "    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2,1)) - I, dim=(1,2)))\n",
    "    return loss\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sim_data = Variable(torch.rand(32,3,2500))\n",
    "    trans = STN3d()\n",
    "    out = trans(sim_data)\n",
    "    print('stn', out.size())\n",
    "    print('loss', feature_transform_regularizer(out))\n",
    "\n",
    "    sim_data_64d = Variable(torch.rand(32, 64, 2500))\n",
    "    trans = STNkd(k=64)\n",
    "    out = trans(sim_data_64d)\n",
    "    print('stn64d', out.size())\n",
    "    print('loss', feature_transform_regularizer(out))\n",
    "\n",
    "    pointfeat = PointNetfeat(global_feat=True)\n",
    "    out, _, _ = pointfeat(sim_data)\n",
    "    print('global feat', out.size())\n",
    "\n",
    "    pointfeat = PointNetfeat(global_feat=False)\n",
    "    out, _, _ = pointfeat(sim_data)\n",
    "    print('point feat', out.size())\n",
    "\n",
    "    cls = PointNetCls(k = 5)\n",
    "    out, _, _ = cls(sim_data)\n",
    "    print('class', out.size())\n",
    "\n",
    "    seg = PointNetDenseCls(k = 3)\n",
    "    out, _, _ = seg(sim_data)\n",
    "    print('seg', out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 500])\n",
      "3\n",
      "torch.Size([32, 500, 1])\n",
      "torch.Size([32, 3, 3])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#batch, dim, npoints\n",
    "sim_data = Variable(torch.rand(32,3,500))\n",
    "print(sim_data.shape)\n",
    "classifier = PointNetDenseCls(k=1, feature_transform=None)\n",
    "output = classifier(sim_data)\n",
    "print(len(output))\n",
    "print (output[0].shape)\n",
    "print (output[1].shape)\n",
    "print (output[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn3d=STN3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "\n",
    "\n",
    "# prepare some coordinates\n",
    "x, y, z = np.indices((8, 8, 3))\n",
    "\n",
    "# draw cuboids in the top left and bottom right corners, and a link between them\n",
    "cube1 = (x < 1) & (y < 1) & (z < 1)\n",
    "cube2 = (x >= 2) & (y >= 2) & (z >= 2)\n",
    "link = abs(x - y) + abs(y - z) + abs(z - x) <= 2\n",
    "\n",
    "# combine the objects into a single boolean array\n",
    "voxels = cube1 | cube2 | link\n",
    "\n",
    "# set the colors of each object\n",
    "colors = np.empty(voxels.shape, dtype=object)\n",
    "colors[link] = 'red'\n",
    "colors[cube1] = 'blue'\n",
    "colors[cube2] = 'green'\n",
    "print(colors.shape)\n",
    "\n",
    "# and plot everything\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.voxels(voxels, facecolors=colors, edgecolor='k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source https://discuss.pytorch.org/t/which-part-of-pytorch-tensor-represents-channels/21778\n",
    "The first number represents the Batchsize (N) and for tensors holding data of a dimension of 1 or above the next dimension is usually referred to as channel-dimension. The following dimensions are commonly height, width and depth.\n",
    "So for 2d data (images) you have a 4d tensor of NxCxHxW which you feed into a 2d conv layer.\n",
    "\n",
    "Note that channels only exist for convolutional layers. Linear layers for example need a shape of N x #num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, n_points=50):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.n_points = n_points\n",
    "        self.conv1 = torch.nn.Conv1d(3, 32, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(32, 16, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(16, 1, 1)\n",
    "        self.lin1 = torch.nn.Linear(n_points, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=0.01, momentum=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #x = torch.max(x, 2, keepdim=True)\n",
    "        x = x.view(batchsize,-1)\n",
    "        #x = x.flatten()\n",
    "        x = F.relu(self.lin1(x))\n",
    "        #print(x.item(), \"TEST\")\n",
    "        return x\n",
    "\n",
    "    def trainbatch(self,x,targets,batchid):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.__call__(x)\n",
    "        loss = self.criterion(output,targets)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.running_loss = loss.item()\n",
    "\n",
    "        if batchid%5 == 0:\n",
    "            print(\"Batch {} - batch loss: {}\".format(batchid, loss))\n",
    "\n",
    "    def train(self, nepochs=5, nbatches=100, device=\"cuda\"):\n",
    "        for epoch in range(nepochs):\n",
    "            self.running_loss = 0.0\n",
    "            for b in range(nbatches):\n",
    "                x = Variable(torch.rand(20,3, self.n_points)).to(device)\n",
    "                targets = torch.rand((20,1)).to(device)\n",
    "                self.trainbatch(x,targets,b)\n",
    "            print(\"Epoch {} - epoch loss: {}\".format(epoch, self.running_loss))\n",
    "\n",
    "    def predict(self,x):\n",
    "        with torch.no_grad():\n",
    "            return self.__call__(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    #sim_data = Variable(torch.rand(2,3,1))\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    #y = torch.ones_like(sim_data, device=device)  # directly create a tensor on GPU\n",
    "    #x = sim_data.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    #print(x)\n",
    "    #print(x.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n",
    "    mymodel.cuda()\n",
    "#print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7],\n",
      "        [6],\n",
      "        [8],\n",
      "        [5],\n",
      "        [4],\n",
      "        [7],\n",
      "        [6],\n",
      "        [9],\n",
      "        [2],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.randint(0,10,(10,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "torch.Size([32, 3, 1])\n",
      "[array(-3.9487555, dtype=float32), array(-0.64513576, dtype=float32), array(4.4414268, dtype=float32), array(0.59656996, dtype=float32), array(0.84263694, dtype=float32), array(0.1799407, dtype=float32), array(-0.33810022, dtype=float32), array(-0.014698, dtype=float32), array(32., dtype=float32), array(0., dtype=float32), array(16., dtype=float32), array(0., dtype=float32)]\n",
      "49.113884\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "params = list(mymodel.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())\n",
    "acc = np.sum([i.sum().cpu().detach().numpy() for i in params])\n",
    "print([i.sum().cpu().detach().numpy() for i in params])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 - batch loss: 0.3382245898246765\n",
      "Batch 5 - batch loss: 0.3181355595588684\n",
      "Batch 10 - batch loss: 0.123971126973629\n",
      "Batch 15 - batch loss: 0.11806805431842804\n",
      "Epoch 0 - epoch loss: 0.08917097002267838\n",
      "Batch 0 - batch loss: 0.10618643462657928\n",
      "Batch 5 - batch loss: 0.13780063390731812\n",
      "Batch 10 - batch loss: 0.07356862723827362\n",
      "Batch 15 - batch loss: 0.09686245769262314\n",
      "Epoch 1 - epoch loss: 0.11616120487451553\n",
      "Batch 0 - batch loss: 0.11314691603183746\n",
      "Batch 5 - batch loss: 0.08725400269031525\n",
      "Batch 10 - batch loss: 0.1038852334022522\n",
      "Batch 15 - batch loss: 0.09339533001184464\n",
      "Epoch 2 - epoch loss: 0.08866983652114868\n",
      "Batch 0 - batch loss: 0.06457017362117767\n",
      "Batch 5 - batch loss: 0.08513413369655609\n",
      "Batch 10 - batch loss: 0.1105044037103653\n",
      "Batch 15 - batch loss: 0.10083504021167755\n",
      "Epoch 3 - epoch loss: 0.10506583750247955\n",
      "Batch 0 - batch loss: 0.1137368306517601\n",
      "Batch 5 - batch loss: 0.11069722473621368\n",
      "Batch 10 - batch loss: 0.07079274952411652\n",
      "Batch 15 - batch loss: 0.10675271600484848\n",
      "Epoch 4 - epoch loss: 0.06510428339242935\n",
      "Batch 0 - batch loss: 0.07760228216648102\n",
      "Batch 5 - batch loss: 0.04861730337142944\n",
      "Batch 10 - batch loss: 0.045040346682071686\n",
      "Batch 15 - batch loss: 0.1273433417081833\n",
      "Epoch 5 - epoch loss: 0.07895804941654205\n",
      "Batch 0 - batch loss: 0.09999040514230728\n",
      "Batch 5 - batch loss: 0.08112189918756485\n",
      "Batch 10 - batch loss: 0.09621183574199677\n",
      "Batch 15 - batch loss: 0.09821252524852753\n",
      "Epoch 6 - epoch loss: 0.12945255637168884\n",
      "Batch 0 - batch loss: 0.06945482641458511\n",
      "Batch 5 - batch loss: 0.11752895265817642\n",
      "Batch 10 - batch loss: 0.07861492782831192\n",
      "Batch 15 - batch loss: 0.06397733837366104\n",
      "Epoch 7 - epoch loss: 0.07917974889278412\n",
      "Batch 0 - batch loss: 0.0900256559252739\n",
      "Batch 5 - batch loss: 0.1035398468375206\n",
      "Batch 10 - batch loss: 0.10485271364450455\n",
      "Batch 15 - batch loss: 0.08228488266468048\n",
      "Epoch 8 - epoch loss: 0.0970112532377243\n",
      "Batch 0 - batch loss: 0.07252119481563568\n",
      "Batch 5 - batch loss: 0.1059158593416214\n",
      "Batch 10 - batch loss: 0.06937892735004425\n",
      "Batch 15 - batch loss: 0.08603028953075409\n",
      "Epoch 9 - epoch loss: 0.10117746889591217\n"
     ]
    }
   ],
   "source": [
    "mymodel.train(10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "MSE 1.5011560916900635\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "x = Variable(torch.rand(20,3,mymodel.n_points)).to(device)\n",
    "targets = torch.rand((20,1)).to(device)\n",
    "y_pred = mymodel.predict(x)\n",
    "print(\"MSE {}\".format(((targets - y_pred)**2).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4961],\n",
       "         [0.4797],\n",
       "         [0.4412],\n",
       "         [0.5206],\n",
       "         [0.5047],\n",
       "         [0.5369],\n",
       "         [0.4553],\n",
       "         [0.5069],\n",
       "         [0.5290],\n",
       "         [0.5432],\n",
       "         [0.4214],\n",
       "         [0.4776],\n",
       "         [0.5100],\n",
       "         [0.5511],\n",
       "         [0.5066],\n",
       "         [0.5555],\n",
       "         [0.4969],\n",
       "         [0.4249],\n",
       "         [0.5324],\n",
       "         [0.4466]], device='cuda:0'), tensor([[0.0617],\n",
       "         [0.4850],\n",
       "         [0.3327],\n",
       "         [0.4573],\n",
       "         [0.9914],\n",
       "         [0.2770],\n",
       "         [0.5478],\n",
       "         [0.3004],\n",
       "         [0.9749],\n",
       "         [0.5455],\n",
       "         [0.3069],\n",
       "         [0.2873],\n",
       "         [0.9876],\n",
       "         [0.9015],\n",
       "         [0.4049],\n",
       "         [0.9054],\n",
       "         [0.4242],\n",
       "         [0.3318],\n",
       "         [0.9694],\n",
       "         [0.5123]], device='cuda:0'))"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
