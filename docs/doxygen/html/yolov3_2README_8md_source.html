<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>GrassRobotics Common: /home/jose/ros_ws/src/gr_perception/gr_ml/nb/yolov3/README.md Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">GrassRobotics Common
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">/home/jose/ros_ws/src/gr_perception/gr_ml/nb/yolov3/README.md</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;**WARNING: This repository has gone stale as I unfortunately do not have the time to maintain it anymore. If you would like to continue the development of it as a collaborator send me an email at eriklindernoren@gmail.com.**</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;# PyTorch-YOLOv3</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;A minimal PyTorch implementation of YOLOv3, with support for training, inference and evaluation.</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;## Installation</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;##### Clone and install requirements</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;    $ git clone https://github.com/eriklindernoren/PyTorch-YOLOv3</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;    $ cd PyTorch-YOLOv3/</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;    $ sudo pip3 install -r requirements.txt</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;##### Download pretrained weights</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;    $ cd weights/</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;    $ bash download_weights.sh</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;##### Download COCO</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;    $ cd data/</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;    $ bash get_coco_dataset.sh</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;    </div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;## Test</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;Evaluates the model on COCO test.</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;    $ python3 test.py --weights_path weights/yolov3.weights</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;| Model                   | mAP (min. 50 IoU) |</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;| ----------------------- |:-----------------:|</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;| YOLOv3 608 (paper)      | 57.9              |</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;| YOLOv3 608 (this impl.) | 57.3              |</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;| YOLOv3 416 (paper)      | 55.3              |</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;| YOLOv3 416 (this impl.) | 55.5              |</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;## Inference</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;Uses pretrained weights to make predictions on images. Below table displays the inference times when using as inputs images scaled to 256x256. The ResNet backbone measurements are taken from the YOLOv3 paper. The Darknet-53 measurement marked shows the inference time of this implementation on my 1080ti card.</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;| Backbone                | GPU      | FPS      |</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;| ----------------------- |:--------:|:--------:|</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;| ResNet-101              | Titan X  | 53       |</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;| ResNet-152              | Titan X  | 37       |</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;| Darknet-53 (paper)      | Titan X  | 76       |</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;| Darknet-53 (this impl.) | 1080ti   | 74       |</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;    $ python3 detect.py --image_folder data/samples/</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;assets/giraffe.png&quot; width=&quot;480&quot;&gt;&lt;/p&gt;</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;assets/dog.png&quot; width=&quot;480&quot;&gt;&lt;/p&gt;</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;assets/traffic.png&quot; width=&quot;480&quot;&gt;&lt;/p&gt;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;assets/messi.png&quot; width=&quot;480&quot;&gt;&lt;/p&gt;</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;## Train</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;```</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;$ train.py [-h] [--epochs EPOCHS] [--batch_size BATCH_SIZE]</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;                [--gradient_accumulations GRADIENT_ACCUMULATIONS]</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;                [--model_def MODEL_DEF] [--data_config DATA_CONFIG]</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;                [--pretrained_weights PRETRAINED_WEIGHTS] [--n_cpu N_CPU]</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;                [--img_size IMG_SIZE]</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;                [--checkpoint_interval CHECKPOINT_INTERVAL]</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;                [--evaluation_interval EVALUATION_INTERVAL]</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;                [--compute_map COMPUTE_MAP]</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;                [--multiscale_training MULTISCALE_TRAINING]</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;```</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;#### Example (COCO)</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;To train on COCO using a Darknet-53 backend pretrained on ImageNet run: </div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;```</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;$ python3 train.py --data_config config/coco.data  --pretrained_weights weights/darknet53.conv.74</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;```</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;#### Training log</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;```</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;---- [Epoch 7/100, Batch 7300/14658] ----</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;+------------+--------------+--------------+--------------+</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;+------------+--------------+--------------+--------------+</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;| grid_size  | 16           | 32           | 64           |</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;| loss       | 1.554926     | 1.446884     | 1.427585     |</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;| x          | 0.028157     | 0.044483     | 0.051159     |</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;| y          | 0.040524     | 0.035687     | 0.046307     |</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;| w          | 0.078980     | 0.066310     | 0.027984     |</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;| h          | 0.133414     | 0.094540     | 0.037121     |</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;| conf       | 1.234448     | 1.165665     | 1.223495     |</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;| cls        | 0.039402     | 0.040198     | 0.041520     |</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;| cls_acc    | 44.44%       | 43.59%       | 32.50%       |</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;| recall50   | 0.361111     | 0.384615     | 0.300000     |</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;| recall75   | 0.222222     | 0.282051     | 0.300000     |</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;| precision  | 0.520000     | 0.300000     | 0.070175     |</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;| conf_obj   | 0.599058     | 0.622685     | 0.651472     |</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;| conf_noobj | 0.003778     | 0.004039     | 0.004044     |</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;+------------+--------------+--------------+--------------+</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;Total Loss 4.429395</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;---- ETA 0:35:48.821929</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;```</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;#### Tensorboard</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;Track training progress in Tensorboard:</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;* Initialize training</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;* Run the command below</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;* Go to http://localhost:6006/</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;```</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;$ tensorboard --logdir=&#39;logs&#39; --port=6006</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;```</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;Storing the logs on a slow drive possibly leads to a significant training speed decrease.</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;You can adjust the log directory using `--logdir &lt;path&gt;` when running `tensorboard` or the `train.py`.</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;## Train on Custom Dataset</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;#### Custom model</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;Run the commands below to create a custom model definition, replacing `&lt;num-classes&gt;` with the number of classes in your dataset.</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;```</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;$ cd config/                                # Navigate to config dir</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;$ bash create_custom_model.sh &lt;num-classes&gt; # Will create custom model &#39;yolov3-custom.cfg&#39;</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;```</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;#### Classes</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;Add class names to `data/custom/classes.names`. This file should have one row per class name.</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;#### Image Folder</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;Move the images of your dataset to `data/custom/images/`.</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;#### Annotation Folder</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;Move your annotations to `data/custom/labels/`. The dataloader expects that the annotation file corresponding to the image `data/custom/images/train.jpg` has the path `data/custom/labels/train.txt`. Each row in the annotation file should define one bounding box, using the syntax `label_idx x_center y_center width height`. The coordinates should be scaled `[0, 1]`, and the `label_idx` should be zero-indexed and correspond to the row number of the class name in `data/custom/classes.names`.</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;#### Define Train and Validation Sets</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;In `data/custom/train.txt` and `data/custom/valid.txt`, add paths to images that will be used as train and validation data respectively.</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;#### Train</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;To train on the custom dataset run:</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;```</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;$ python3 train.py --model_def config/yolov3-custom.cfg --data_config config/custom.data</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;```</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;Add `--pretrained_weights weights/darknet53.conv.74` to train using a backend pretrained on ImageNet.</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;## Credit</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;### YOLOv3: An Incremental Improvement</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;_Joseph Redmon, Ali Farhadi_ &lt;br&gt;</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;**Abstract** &lt;br&gt;</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;We present some updates to YOLO! We made a bunch</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;of little design changes to make it better. We also trained</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;this new network that’s pretty swell. It’s a little bigger than</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;last time but more accurate. It’s still fast though, don’t</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;worry. At 320 × 320 YOLOv3 runs in 22 ms at 28.2 mAP,</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;as accurate as SSD but three times faster. When we look</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;at the old .5 IOU mAP detection metric YOLOv3 is quite</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;good. It achieves 57.9 AP50 in 51 ms on a Titan X, compared</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;to 57.5 AP50 in 198 ms by RetinaNet, similar performance</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;but 3.8× faster. As always, all the code is online at</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;https://pjreddie.com/yolo/.</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;[[Paper]](https://pjreddie.com/media/files/papers/YOLOv3.pdf) [[Project Webpage]](https://pjreddie.com/darknet/yolo/) [[Authors&#39; Implementation]](https://github.com/pjreddie/darknet)</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;```</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;@article{yolov3,</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;  title={YOLOv3: An Incremental Improvement},</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;  author={Redmon, Joseph and Farhadi, Ali},</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;  journal = {arXiv},</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;  year={2018}</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;}</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;```</div></div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
