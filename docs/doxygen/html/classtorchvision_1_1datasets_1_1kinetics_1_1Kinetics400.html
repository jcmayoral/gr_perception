<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>GrassRobotics Common: torchvision.datasets.kinetics.Kinetics400 Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">GrassRobotics Common
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>torchvision</b></li><li class="navelem"><b>datasets</b></li><li class="navelem"><b>kinetics</b></li><li class="navelem"><a class="el" href="classtorchvision_1_1datasets_1_1kinetics_1_1Kinetics400.html">Kinetics400</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Data Fields</a>  </div>
  <div class="headertitle">
<div class="title">torchvision.datasets.kinetics.Kinetics400 Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for torchvision.datasets.kinetics.Kinetics400:</div>
<div class="dyncontent">
<div class="center"><img src="classtorchvision_1_1datasets_1_1kinetics_1_1Kinetics400__inherit__graph.png" border="0" usemap="#torchvision_8datasets_8kinetics_8Kinetics400_inherit__map" alt="Inheritance graph"/></div>
<map name="torchvision_8datasets_8kinetics_8Kinetics400_inherit__map" id="torchvision_8datasets_8kinetics_8Kinetics400_inherit__map">
<area shape="rect" id="node2" href="classtorchvision_1_1datasets_1_1vision_1_1VisionDataset.html" title="torchvision.datasets.vision.\lVisionDataset" alt="" coords="11,80,192,121"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for torchvision.datasets.kinetics.Kinetics400:</div>
<div class="dyncontent">
<div class="center"><img src="classtorchvision_1_1datasets_1_1kinetics_1_1Kinetics400__coll__graph.png" border="0" usemap="#torchvision_8datasets_8kinetics_8Kinetics400_coll__map" alt="Collaboration graph"/></div>
<map name="torchvision_8datasets_8kinetics_8Kinetics400_coll__map" id="torchvision_8datasets_8kinetics_8Kinetics400_coll__map">
<area shape="rect" id="node2" href="classtorchvision_1_1datasets_1_1vision_1_1VisionDataset.html" title="torchvision.datasets.vision.\lVisionDataset" alt="" coords="11,80,192,121"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a7c7955c8a0f7fe8932305a7916d9ca08"><td class="memItemLeft" align="right" valign="top"><a id="a7c7955c8a0f7fe8932305a7916d9ca08"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__init__</b> (self, root, frames_per_clip, step_between_clips=1, frame_rate=None, extensions=('avi',), transform=None, _precomputed_metadata=None, num_workers=1, _video_width=0, _video_height=0, _video_min_dimension=0, _audio_samples=0, _audio_channels=0)</td></tr>
<tr class="separator:a7c7955c8a0f7fe8932305a7916d9ca08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acea1d298f6dc8393bbe3ec55a7d6b4bf"><td class="memItemLeft" align="right" valign="top"><a id="acea1d298f6dc8393bbe3ec55a7d6b4bf"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>metadata</b> (self)</td></tr>
<tr class="separator:acea1d298f6dc8393bbe3ec55a7d6b4bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d28fc93b3e79778847247b2188e4c7f"><td class="memItemLeft" align="right" valign="top"><a id="a2d28fc93b3e79778847247b2188e4c7f"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__len__</b> (self)</td></tr>
<tr class="separator:a2d28fc93b3e79778847247b2188e4c7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ff04f001e56fb7e27c98b928c0bb768"><td class="memItemLeft" align="right" valign="top"><a id="a1ff04f001e56fb7e27c98b928c0bb768"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__getitem__</b> (self, idx)</td></tr>
<tr class="separator:a1ff04f001e56fb7e27c98b928c0bb768"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classtorchvision_1_1datasets_1_1vision_1_1VisionDataset.html">torchvision.datasets.vision.VisionDataset</a></td></tr>
<tr class="memitem:afaab2235a0f5195628c1dc2f77c0c374 inherit pub_methods_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memItemLeft" align="right" valign="top"><a id="afaab2235a0f5195628c1dc2f77c0c374"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__init__</b> (self, root, transforms=None, transform=None, target_transform=None)</td></tr>
<tr class="separator:afaab2235a0f5195628c1dc2f77c0c374 inherit pub_methods_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12602844a432d9bd7659a7756550b709 inherit pub_methods_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memItemLeft" align="right" valign="top"><a id="a12602844a432d9bd7659a7756550b709"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__getitem__</b> (self, index)</td></tr>
<tr class="separator:a12602844a432d9bd7659a7756550b709 inherit pub_methods_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa665e0a455393e4dfb3f419a59dff23b inherit pub_methods_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memItemLeft" align="right" valign="top"><a id="aa665e0a455393e4dfb3f419a59dff23b"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__len__</b> (self)</td></tr>
<tr class="separator:aa665e0a455393e4dfb3f419a59dff23b inherit pub_methods_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0364a479c896f3016d1137846c419cc inherit pub_methods_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memItemLeft" align="right" valign="top"><a id="aa0364a479c896f3016d1137846c419cc"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__repr__</b> (self)</td></tr>
<tr class="separator:aa0364a479c896f3016d1137846c419cc inherit pub_methods_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7bfd92c0784ec2cf80825638f2095738 inherit pub_methods_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memItemLeft" align="right" valign="top"><a id="a7bfd92c0784ec2cf80825638f2095738"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>extra_repr</b> (self)</td></tr>
<tr class="separator:a7bfd92c0784ec2cf80825638f2095738 inherit pub_methods_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Data Fields</h2></td></tr>
<tr class="memitem:a73a9781ac6c64d891ea6ad6bcbdf168c"><td class="memItemLeft" align="right" valign="top"><a id="a73a9781ac6c64d891ea6ad6bcbdf168c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>samples</b></td></tr>
<tr class="separator:a73a9781ac6c64d891ea6ad6bcbdf168c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a829eb6d6f69ce1811510d7f58e240168"><td class="memItemLeft" align="right" valign="top"><a id="a829eb6d6f69ce1811510d7f58e240168"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>classes</b></td></tr>
<tr class="separator:a829eb6d6f69ce1811510d7f58e240168"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad17b7a4ea9ecd998daa15a48673ba226"><td class="memItemLeft" align="right" valign="top"><a id="ad17b7a4ea9ecd998daa15a48673ba226"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>video_clips</b></td></tr>
<tr class="separator:ad17b7a4ea9ecd998daa15a48673ba226"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1b5546bb5850ae013c901bb481ec642"><td class="memItemLeft" align="right" valign="top"><a id="ac1b5546bb5850ae013c901bb481ec642"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>transform</b></td></tr>
<tr class="separator:ac1b5546bb5850ae013c901bb481ec642"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset')"><img src="closed.png" alt="-"/>&#160;Data Fields inherited from <a class="el" href="classtorchvision_1_1datasets_1_1vision_1_1VisionDataset.html">torchvision.datasets.vision.VisionDataset</a></td></tr>
<tr class="memitem:a6abb4f738f2e42d0c87449a2ea18d0bd inherit pub_attribs_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memItemLeft" align="right" valign="top"><a id="a6abb4f738f2e42d0c87449a2ea18d0bd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>root</b></td></tr>
<tr class="separator:a6abb4f738f2e42d0c87449a2ea18d0bd inherit pub_attribs_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03de25aa3644bca2612cc4236a77b0c0 inherit pub_attribs_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memItemLeft" align="right" valign="top"><a id="a03de25aa3644bca2612cc4236a77b0c0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>transform</b></td></tr>
<tr class="separator:a03de25aa3644bca2612cc4236a77b0c0 inherit pub_attribs_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea9eff124fe2b0848e6aa29bf6395dc2 inherit pub_attribs_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memItemLeft" align="right" valign="top"><a id="aea9eff124fe2b0848e6aa29bf6395dc2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>target_transform</b></td></tr>
<tr class="separator:aea9eff124fe2b0848e6aa29bf6395dc2 inherit pub_attribs_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a16f87b3136f02d09188d8d33917a7e12 inherit pub_attribs_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memItemLeft" align="right" valign="top"><a id="a16f87b3136f02d09188d8d33917a7e12"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>transforms</b></td></tr>
<tr class="separator:a16f87b3136f02d09188d8d33917a7e12 inherit pub_attribs_classtorchvision_1_1datasets_1_1vision_1_1VisionDataset"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">`Kinetics-400 &lt;https://deepmind.com/research/open-source/open-source-datasets/kinetics/&gt;`_
dataset.

Kinetics-400 is an action recognition video dataset.
This dataset consider every video as a collection of video clips of fixed size, specified
by ``frames_per_clip``, where the step in frames between each clip is given by
``step_between_clips``.

To give an example, for 2 videos with 10 and 15 frames respectively, if ``frames_per_clip=5``
and ``step_between_clips=5``, the dataset size will be (2 + 3) = 5, where the first two
elements will come from video 1, and the next three elements from video 2.
Note that we drop clips which do not have exactly ``frames_per_clip`` elements, so not all
frames in a video might be present.

Internally, it uses a VideoClips object to handle clip creation.

Args:
    root (string): Root directory of the Kinetics-400 Dataset.
    frames_per_clip (int): number of frames in a clip
    step_between_clips (int): number of frames between each clip
    transform (callable, optional): A function/transform that  takes in a TxHxWxC video
        and returns a transformed version.

Returns:
    video (Tensor[T, H, W, C]): the `T` video frames
    audio(Tensor[K, L]): the audio frames, where `K` is the number of channels
        and `L` is the number of points
    label (int): class of the video clip
</pre> 
<p class="definition">Definition at line <a class="el" href="kinetics_8py_source.html#l00007">7</a> of file <a class="el" href="kinetics_8py_source.html">kinetics.py</a>.</p>
</div><hr/>The documentation for this class was generated from the following file:<ul>
<li>/home/jose/ros_ws/src/gr_perception/gr_ml/nb/vision/torchvision/datasets/<a class="el" href="kinetics_8py_source.html">kinetics.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
