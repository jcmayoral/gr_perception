\hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset}{}\section{torchvision.\+datasets.\+sbd.\+S\+B\+Dataset Class Reference}
\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset}\index{torchvision.\+datasets.\+sbd.\+S\+B\+Dataset@{torchvision.\+datasets.\+sbd.\+S\+B\+Dataset}}


Inheritance diagram for torchvision.\+datasets.\+sbd.\+S\+B\+Dataset\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=216pt]{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for torchvision.\+datasets.\+sbd.\+S\+B\+Dataset\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=216pt]{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a8d25e4094ecd4d5ba455605afd52e8e5}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a8d25e4094ecd4d5ba455605afd52e8e5}} 
def {\bfseries \+\_\+\+\_\+init\+\_\+\+\_\+} (self, root, image\+\_\+set=\textquotesingle{}train\textquotesingle{}, mode=\textquotesingle{}boundaries\textquotesingle{}, download=False, transforms=None)
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a21e18bb60168bbc3d47ad8ce12170acf}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a21e18bb60168bbc3d47ad8ce12170acf}} 
def {\bfseries \+\_\+\+\_\+getitem\+\_\+\+\_\+} (self, index)
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a40a0783ec86deb01a2fc3a015a8ca6bd}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a40a0783ec86deb01a2fc3a015a8ca6bd}} 
def {\bfseries \+\_\+\+\_\+len\+\_\+\+\_\+} (self)
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a95e307cf8b6617854be52aba6c6b5a8d}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a95e307cf8b6617854be52aba6c6b5a8d}} 
def {\bfseries extra\+\_\+repr} (self)
\end{DoxyCompactItemize}
\subsection*{Data Fields}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_aba43cdefe63eb965439d3529e8a44f05}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_aba43cdefe63eb965439d3529e8a44f05}} 
{\bfseries image\+\_\+set}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_af108bef4fa2029ad112d2bdcaa2751a9}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_af108bef4fa2029ad112d2bdcaa2751a9}} 
{\bfseries mode}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a8e72302efa558e3cf3b1ea7643d3a468}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a8e72302efa558e3cf3b1ea7643d3a468}} 
{\bfseries num\+\_\+classes}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a86d2a73e7a375813b69c6216ff172a20}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a86d2a73e7a375813b69c6216ff172a20}} 
{\bfseries images}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a66d5767d6daf41688630662313163b00}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a66d5767d6daf41688630662313163b00}} 
{\bfseries masks}
\end{DoxyCompactItemize}
\subsection*{Static Public Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a54fcc50b1691795709aab3acb4634f74}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a54fcc50b1691795709aab3acb4634f74}} 
{\bfseries url}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a058ec5f1706dd1e5639e354b4e128a9e}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a058ec5f1706dd1e5639e354b4e128a9e}} 
{\bfseries md5}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_ae1a04b8274e8d3fd0d853188cbc1549f}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_ae1a04b8274e8d3fd0d853188cbc1549f}} 
{\bfseries filename}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a6e311d6f6f1ecd17e81ad8e83754da31}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a6e311d6f6f1ecd17e81ad8e83754da31}} 
{\bfseries voc\+\_\+train\+\_\+url}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a82a5f014ee1bef0b9cc217ea0667cf1b}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_a82a5f014ee1bef0b9cc217ea0667cf1b}} 
{\bfseries voc\+\_\+split\+\_\+filename}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_acd5cbb3dad7c6d1cded354bdbb22cc3a}\label{classtorchvision_1_1datasets_1_1sbd_1_1SBDataset_acd5cbb3dad7c6d1cded354bdbb22cc3a}} 
{\bfseries voc\+\_\+split\+\_\+md5}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}`Semantic Boundaries Dataset <http://home.bharathh.info/pubs/codes/SBD/download.html>`_

The SBD currently contains annotations from 11355 images taken from the PASCAL VOC 2011 dataset.

.. note ::

    Please note that the train and val splits included with this dataset are different from
    the splits in the PASCAL VOC dataset. In particular some "train" images might be part of
    VOC2012 val.
    If you are interested in testing on VOC 2012 val, then use `image_set='train_noval'`,
    which excludes all val images.

.. warning::

    This class needs `scipy <https://docs.scipy.org/doc/>`_ to load target files from `.mat` format.

Args:
    root (string): Root directory of the Semantic Boundaries Dataset
    image_set (string, optional): Select the image_set to use, ``train``, ``val`` or ``train_noval``.
        Image set ``train_noval`` excludes VOC 2012 val images.
    mode (string, optional): Select target type. Possible values 'boundaries' or 'segmentation'.
        In case of 'boundaries', the target is an array of shape `[num_classes, H, W]`,
        where `num_classes=20`.
    download (bool, optional): If true, downloads the dataset from the internet and
        puts it in root directory. If dataset is already downloaded, it is not
        downloaded again.
    transforms (callable, optional): A function/transform that takes input sample and its target as entry
        and returns a transformed version. Input sample is PIL image and target is a numpy array
        if `mode='boundaries'` or PIL image if `mode='segmentation'`.
\end{DoxyVerb}
 

Definition at line 12 of file sbd.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/jose/ros\+\_\+ws/src/gr\+\_\+perception/gr\+\_\+ml/nb/vision/torchvision/datasets/sbd.\+py\end{DoxyCompactItemize}
