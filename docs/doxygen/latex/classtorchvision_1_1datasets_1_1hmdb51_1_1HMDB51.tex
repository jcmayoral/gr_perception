\hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51}{}\section{torchvision.\+datasets.\+hmdb51.\+H\+M\+D\+B51 Class Reference}
\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51}\index{torchvision.\+datasets.\+hmdb51.\+H\+M\+D\+B51@{torchvision.\+datasets.\+hmdb51.\+H\+M\+D\+B51}}


Inheritance diagram for torchvision.\+datasets.\+hmdb51.\+H\+M\+D\+B51\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=225pt]{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for torchvision.\+datasets.\+hmdb51.\+H\+M\+D\+B51\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=225pt]{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_af398139908199f098c53560bbb910ea7}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_af398139908199f098c53560bbb910ea7}} 
def {\bfseries \+\_\+\+\_\+init\+\_\+\+\_\+} (self, root, annotation\+\_\+path, frames\+\_\+per\+\_\+clip, step\+\_\+between\+\_\+clips=1, frame\+\_\+rate=None, fold=1, train=True, transform=None, \+\_\+precomputed\+\_\+metadata=None, num\+\_\+workers=1, \+\_\+video\+\_\+width=0, \+\_\+video\+\_\+height=0, \+\_\+video\+\_\+min\+\_\+dimension=0, \+\_\+audio\+\_\+samples=0)
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_aad29ef51a2bb523c564cb48a869814c7}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_aad29ef51a2bb523c564cb48a869814c7}} 
def {\bfseries metadata} (self)
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_ab25c14a6fe9f181278d74e266bdc658d}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_ab25c14a6fe9f181278d74e266bdc658d}} 
def {\bfseries \+\_\+\+\_\+len\+\_\+\+\_\+} (self)
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a3ccf3a6dedb7b1a30099117d0c331c35}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a3ccf3a6dedb7b1a30099117d0c331c35}} 
def {\bfseries \+\_\+\+\_\+getitem\+\_\+\+\_\+} (self, idx)
\end{DoxyCompactItemize}
\subsection*{Data Fields}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a046a2a495ce9b73cf2cbf787bd69cf4b}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a046a2a495ce9b73cf2cbf787bd69cf4b}} 
{\bfseries samples}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a7602da59e3ea1052465262d646f3de8d}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a7602da59e3ea1052465262d646f3de8d}} 
{\bfseries fold}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_aedf0a21c31798fd14ea9fed3c12ea9ce}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_aedf0a21c31798fd14ea9fed3c12ea9ce}} 
{\bfseries train}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a1e9b9c7123774e034a430c5ea6368af1}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a1e9b9c7123774e034a430c5ea6368af1}} 
{\bfseries classes}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_ab6c423d82cffc1c09ccd3280ec17ebe8}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_ab6c423d82cffc1c09ccd3280ec17ebe8}} 
{\bfseries video\+\_\+clips\+\_\+metadata}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a2857375f37bdf955d21afdfdb6ca4844}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a2857375f37bdf955d21afdfdb6ca4844}} 
{\bfseries indices}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a6016cd8a8433d30898ed579d1dafc80a}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a6016cd8a8433d30898ed579d1dafc80a}} 
{\bfseries video\+\_\+clips}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_ae8a69722c6ae43cdac97eb4bbe11bd98}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_ae8a69722c6ae43cdac97eb4bbe11bd98}} 
{\bfseries transform}
\end{DoxyCompactItemize}
\subsection*{Static Public Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a7ed1a32571059b922f444ced182a362f}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a7ed1a32571059b922f444ced182a362f}} 
{\bfseries data\+\_\+url}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_ac93f47364c547263118cae4868b20f43}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_ac93f47364c547263118cae4868b20f43}} 
{\bfseries splits}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a50f2fd7c1e45b040af440b67b5411bb7}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a50f2fd7c1e45b040af440b67b5411bb7}} 
{\bfseries T\+R\+A\+I\+N\+\_\+\+T\+AG}
\item 
\mbox{\Hypertarget{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a6bfe3e3fc8601ef054b18a0ed47179fb}\label{classtorchvision_1_1datasets_1_1hmdb51_1_1HMDB51_a6bfe3e3fc8601ef054b18a0ed47179fb}} 
{\bfseries T\+E\+S\+T\+\_\+\+T\+AG}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}`HMDB51 <http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/>`_
dataset.

HMDB51 is an action recognition video dataset.
This dataset consider every video as a collection of video clips of fixed size, specified
by ``frames_per_clip``, where the step in frames between each clip is given by
``step_between_clips``.

To give an example, for 2 videos with 10 and 15 frames respectively, if ``frames_per_clip=5``
and ``step_between_clips=5``, the dataset size will be (2 + 3) = 5, where the first two
elements will come from video 1, and the next three elements from video 2.
Note that we drop clips which do not have exactly ``frames_per_clip`` elements, so not all
frames in a video might be present.

Internally, it uses a VideoClips object to handle clip creation.

Args:
    root (string): Root directory of the HMDB51 Dataset.
    annotation_path (str): Path to the folder containing the split files.
    frames_per_clip (int): Number of frames in a clip.
    step_between_clips (int): Number of frames between each clip.
    fold (int, optional): Which fold to use. Should be between 1 and 3.
    train (bool, optional): If ``True``, creates a dataset from the train split,
        otherwise from the ``test`` split.
    transform (callable, optional): A function/transform that takes in a TxHxWxC video
        and returns a transformed version.

Returns:
    video (Tensor[T, H, W, C]): the `T` video frames
    audio(Tensor[K, L]): the audio frames, where `K` is the number of channels
        and `L` is the number of points
    label (int): class of the video clip
\end{DoxyVerb}
 

Definition at line 10 of file hmdb51.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/jose/ros\+\_\+ws/src/gr\+\_\+perception/gr\+\_\+ml/nb/vision/torchvision/datasets/hmdb51.\+py\end{DoxyCompactItemize}
