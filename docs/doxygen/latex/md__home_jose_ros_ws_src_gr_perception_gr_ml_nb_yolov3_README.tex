$\ast$$\ast$\+W\+A\+R\+N\+I\+NG\+: This repository has gone stale as I unfortunately do not have the time to maintain it anymore. If you would like to continue the development of it as a collaborator send me an email at \href{mailto:eriklindernoren@gmail.com}{\tt eriklindernoren@gmail.\+com}.$\ast$$\ast$

\section*{Py\+Torch-\/\+Y\+O\+L\+Ov3}

A minimal Py\+Torch implementation of Y\+O\+L\+Ov3, with support for training, inference and evaluation.

\subsection*{Installation}

\subparagraph*{Clone and install requirements}

\$ git clone \href{https://github.com/eriklindernoren/PyTorch-YOLOv3}{\tt https\+://github.\+com/eriklindernoren/\+Py\+Torch-\/\+Y\+O\+L\+Ov3} \$ cd Py\+Torch-\/\+Y\+O\+L\+Ov3/ \$ sudo pip3 install -\/r requirements.\+txt

\subparagraph*{Download pretrained weights}

\$ cd weights/ \$ bash download\+\_\+weights.\+sh

\subparagraph*{Download C\+O\+CO}

\$ cd data/ \$ bash get\+\_\+coco\+\_\+dataset.\+sh

\subsection*{Test}

Evaluates the model on C\+O\+CO test. \begin{DoxyVerb}$ python3 test.py --weights_path weights/yolov3.weights
\end{DoxyVerb}


\tabulinesep=1mm
\begin{longtabu} spread 0pt [c]{*{2}{|X[-1]}|}
\hline
\rowcolor{\tableheadbgcolor}\textbf{ Model }&\PBS\centering \textbf{ m\+AP (min. 50 IoU)  }\\\cline{1-2}
\endfirsthead
\hline
\endfoot
\hline
\rowcolor{\tableheadbgcolor}\textbf{ Model }&\PBS\centering \textbf{ m\+AP (min. 50 IoU)  }\\\cline{1-2}
\endhead
Y\+O\+L\+Ov3 608 (paper) &\PBS\centering 57.\+9 \\\cline{1-2}
Y\+O\+L\+Ov3 608 (this impl.) &\PBS\centering 57.\+3 \\\cline{1-2}
Y\+O\+L\+Ov3 416 (paper) &\PBS\centering 55.\+3 \\\cline{1-2}
Y\+O\+L\+Ov3 416 (this impl.) &\PBS\centering 55.\+5 \\\cline{1-2}
\end{longtabu}
\subsection*{Inference}

Uses pretrained weights to make predictions on images. Below table displays the inference times when using as inputs images scaled to 256x256. The Res\+Net backbone measurements are taken from the Y\+O\+L\+Ov3 paper. The Darknet-\/53 measurement marked shows the inference time of this implementation on my 1080ti card.

\tabulinesep=1mm
\begin{longtabu} spread 0pt [c]{*{3}{|X[-1]}|}
\hline
\rowcolor{\tableheadbgcolor}\textbf{ Backbone }&\PBS\centering \textbf{ G\+PU }&\PBS\centering \textbf{ F\+PS  }\\\cline{1-3}
\endfirsthead
\hline
\endfoot
\hline
\rowcolor{\tableheadbgcolor}\textbf{ Backbone }&\PBS\centering \textbf{ G\+PU }&\PBS\centering \textbf{ F\+PS  }\\\cline{1-3}
\endhead
Res\+Net-\/101 &\PBS\centering Titan X &\PBS\centering 53 \\\cline{1-3}
Res\+Net-\/152 &\PBS\centering Titan X &\PBS\centering 37 \\\cline{1-3}
Darknet-\/53 (paper) &\PBS\centering Titan X &\PBS\centering 76 \\\cline{1-3}
Darknet-\/53 (this impl.) &\PBS\centering 1080ti &\PBS\centering 74 \\\cline{1-3}
\end{longtabu}
\begin{DoxyVerb}$ python3 detect.py --image_folder data/samples/
\end{DoxyVerb}


$<$img src=\char`\"{}assets/giraffe.\+png\char`\"{} width=\char`\"{}480\char`\"{}$>$

$<$img src=\char`\"{}assets/dog.\+png\char`\"{} width=\char`\"{}480\char`\"{}$>$

$<$img src=\char`\"{}assets/traffic.\+png\char`\"{} width=\char`\"{}480\char`\"{}$>$

$<$img src=\char`\"{}assets/messi.\+png\char`\"{} width=\char`\"{}480\char`\"{}$>$

\#\# Train 
\begin{DoxyCode}
$ train.py [-h] [--epochs EPOCHS] [--batch\_size BATCH\_SIZE]
                [--gradient\_accumulations GRADIENT\_ACCUMULATIONS]
                [--model\_def MODEL\_DEF] [--data\_config DATA\_CONFIG]
                [--pretrained\_weights PRETRAINED\_WEIGHTS] [--n\_cpu N\_CPU]
                [--img\_size IMG\_SIZE]
                [--checkpoint\_interval CHECKPOINT\_INTERVAL]
                [--evaluation\_interval EVALUATION\_INTERVAL]
                [--compute\_map COMPUTE\_MAP]
                [--multiscale\_training MULTISCALE\_TRAINING]
\end{DoxyCode}


\paragraph*{Example (C\+O\+CO)}

To train on C\+O\+CO using a Darknet-\/53 backend pretrained on Image\+Net run\+: 
\begin{DoxyCode}
$ python3 train.py --data\_config config/coco.data  --pretrained\_weights weights/darknet53.conv.74
\end{DoxyCode}


\#\#\#\# Training log 
\begin{DoxyCode}
---- [Epoch 7/100, Batch 7300/14658] ----
+------------+--------------+--------------+--------------+
| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |
+------------+--------------+--------------+--------------+
| grid\_size  | 16           | 32           | 64           |
| loss       | 1.554926     | 1.446884     | 1.427585     |
| x          | 0.028157     | 0.044483     | 0.051159     |
| y          | 0.040524     | 0.035687     | 0.046307     |
| w          | 0.078980     | 0.066310     | 0.027984     |
| h          | 0.133414     | 0.094540     | 0.037121     |
| conf       | 1.234448     | 1.165665     | 1.223495     |
| cls        | 0.039402     | 0.040198     | 0.041520     |
| cls\_acc    | 44.44%       | 43.59%       | 32.50%       |
| recall50   | 0.361111     | 0.384615     | 0.300000     |
| recall75   | 0.222222     | 0.282051     | 0.300000     |
| precision  | 0.520000     | 0.300000     | 0.070175     |
| conf\_obj   | 0.599058     | 0.622685     | 0.651472     |
| conf\_noobj | 0.003778     | 0.004039     | 0.004044     |
+------------+--------------+--------------+--------------+
Total Loss 4.429395
---- ETA 0:35:48.821929
\end{DoxyCode}


\paragraph*{Tensorboard}

Track training progress in Tensorboard\+:
\begin{DoxyItemize}
\item Initialize training
\item Run the command below
\item Go to \href{http://localhost:6006/}{\tt http\+://localhost\+:6006/}
\end{DoxyItemize}


\begin{DoxyCode}
$ tensorboard --logdir='logs' --port=6006
\end{DoxyCode}


Storing the logs on a slow drive possibly leads to a significant training speed decrease.

You can adjust the log directory using {\ttfamily -\/-\/logdir $<$path$>$} when running {\ttfamily tensorboard} or the {\ttfamily train.\+py}.

\subsection*{Train on Custom Dataset}

\paragraph*{Custom model}

Run the commands below to create a custom model definition, replacing {\ttfamily $<$num-\/classes$>$} with the number of classes in your dataset.


\begin{DoxyCode}
$ cd config/                                # Navigate to config dir
$ bash create\_custom\_model.sh <num-classes> # Will create custom model 'yolov3-custom.cfg'
\end{DoxyCode}


\paragraph*{Classes}

Add class names to {\ttfamily data/custom/classes.\+names}. This file should have one row per class name.

\paragraph*{Image Folder}

Move the images of your dataset to {\ttfamily data/custom/images/}.

\paragraph*{Annotation Folder}

Move your annotations to {\ttfamily data/custom/labels/}. The dataloader expects that the annotation file corresponding to the image {\ttfamily data/custom/images/train.\+jpg} has the path {\ttfamily data/custom/labels/train.\+txt}. Each row in the annotation file should define one bounding box, using the syntax {\ttfamily label\+\_\+idx x\+\_\+center y\+\_\+center width height}. The coordinates should be scaled {\ttfamily \mbox{[}0, 1\mbox{]}}, and the {\ttfamily label\+\_\+idx} should be zero-\/indexed and correspond to the row number of the class name in {\ttfamily data/custom/classes.\+names}.

\paragraph*{Define Train and Validation Sets}

In {\ttfamily data/custom/train.\+txt} and {\ttfamily data/custom/valid.\+txt}, add paths to images that will be used as train and validation data respectively.

\paragraph*{Train}

To train on the custom dataset run\+:


\begin{DoxyCode}
$ python3 train.py --model\_def config/yolov3-custom.cfg --data\_config config/custom.data
\end{DoxyCode}


Add {\ttfamily -\/-\/pretrained\+\_\+weights weights/darknet53.\+conv.\+74} to train using a backend pretrained on Image\+Net.

\subsection*{Credit}

\subsubsection*{Y\+O\+L\+Ov3\+: An Incremental Improvement}

{\itshape Joseph Redmon, Ali Farhadi} ~\newline


{\bfseries Abstract} ~\newline
 We present some updates to Y\+O\+L\+O! We made a bunch of little design changes to make it better. We also trained this new network that’s pretty swell. It’s a little bigger than last time but more accurate. It’s still fast though, don’t worry. At 320 × 320 Y\+O\+L\+Ov3 runs in 22 ms at 28.\+2 m\+AP, as accurate as S\+SD but three times faster. When we look at the old .5 I\+OU m\+AP detection metric Y\+O\+L\+Ov3 is quite good. It achieves 57.\+9 A\+P50 in 51 ms on a Titan X, compared to 57.\+5 A\+P50 in 198 ms by Retina\+Net, similar performance but 3.\+8× faster. As always, all the code is online at \href{https://pjreddie.com/yolo/}{\tt https\+://pjreddie.\+com/yolo/}.

\href{https://pjreddie.com/media/files/papers/YOLOv3.pdf}{\tt \mbox{[}Paper\mbox{]}} \href{https://pjreddie.com/darknet/yolo/}{\tt \mbox{[}Project Webpage\mbox{]}} \href{https://github.com/pjreddie/darknet}{\tt \mbox{[}Authors\textquotesingle{} Implementation\mbox{]}}


\begin{DoxyCode}
@article\{yolov3,
  title=\{YOLOv3: An Incremental Improvement\},
  author=\{Redmon, Joseph and Farhadi, Ali\},
  journal = \{arXiv\},
  year=\{2018\}
\}
\end{DoxyCode}
 